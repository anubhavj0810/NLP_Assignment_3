{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Sentiment_Analyser.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOXWmn_wZrGV",
        "colab_type": "code",
        "outputId": "f20bf814-e86c-43b0-f241-bdece3b796a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import keras.callbacks\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dense, Input, Dropout, MaxPooling1D, Conv1D, GlobalMaxPool1D\n",
        "from keras.layers import LSTM, Lambda, concatenate, TimeDistributed, Bidirectional"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7V7qgfOxIdD",
        "colab_type": "code",
        "outputId": "7a808937-cc22-4c95-a864-d2cedbc12913",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0NWLIa5vbAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from keras.layers import Input, Embedding, Activation, Flatten, Dense\n",
        "from keras.layers import Conv1D, MaxPooling1D, Dropout\n",
        "from keras.models import Model\n",
        "from keras.layers import LeakyReLU\n",
        "\n",
        "train_data_source = '/content/drive/My Drive/nlp_assignment_3/train.csv'\n",
        "test_data_source = '/content/drive/My Drive/nlp_assignment_3/test.csv'\n",
        "\n",
        "train_df = pd.read_csv(train_data_source, delimiter=\"\\t\")\n",
        "test_df = pd.read_csv(test_data_source, delimiter=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rmjp_bmexlI0",
        "colab_type": "code",
        "outputId": "512f2ded-21f6-42c1-f84e-9740f1a4ea20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>meta</th>\n",
              "      <th>uid</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>meta</td>\n",
              "      <td>3</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@</td>\n",
              "      <td>O</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AdilNisarButt</td>\n",
              "      <td>Hin</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pakistan</td>\n",
              "      <td>Hin</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ka</td>\n",
              "      <td>Hin</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            meta  uid sentiment\n",
              "0           meta    3  negative\n",
              "1              @    O       NaN\n",
              "2  AdilNisarButt  Hin       NaN\n",
              "3       pakistan  Hin       NaN\n",
              "4             ka  Hin       NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nglFKD6gPzuK",
        "colab_type": "code",
        "outputId": "2b02d697-ab8c-4289-db76-cbd7dd57206a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>meta</th>\n",
              "      <th>uid</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>meta</td>\n",
              "      <td>8</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RT</td>\n",
              "      <td>Eng</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@</td>\n",
              "      <td>O</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>UAAPconfessions</td>\n",
              "      <td>Eng</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Love</td>\n",
              "      <td>Eng</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              meta  uid sentiment\n",
              "0             meta    8   neutral\n",
              "1               RT  Eng       NaN\n",
              "2                @    O       NaN\n",
              "3  UAAPconfessions  Eng       NaN\n",
              "4             Love  Eng       NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Pm8gQh2LaF4",
        "colab_type": "code",
        "outputId": "2c3c23ad-18b2-417a-f97e-d285d0262d1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "string = \"\"\n",
        "a = train_df.loc[:,['meta','sentiment']]\n",
        "temp = \"\"\n",
        "train_arr = []\n",
        "train_arr_senti = []\n",
        "\n",
        "for i in range(a.shape[0]):\n",
        "  if(a.iloc[i,0]==\"meta\"):\n",
        "    #print(a.iloc[i,0])\n",
        "    train_arr.append(temp)\n",
        "    train_arr_senti.append(str(a.iloc[i,1]))\n",
        "    temp=\"\"\n",
        "  else:\n",
        "    temp+=str(a.iloc[i,0])+\" \"\n",
        "\n",
        "train_arr.append(temp)\n",
        "train_arr=train_arr[1:]\n",
        "print(train_arr[0],train_arr_senti[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@ AdilNisarButt pakistan ka ghra tauq he Pakistan Israel ko tasleem nahein kerta Isko Palestine kehta he - OCCUPIED PALESTINE  negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_7YZXfvPws6",
        "colab_type": "code",
        "outputId": "9c085fe9-f299-41fb-c578-b789f438868d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "string = \"\"\n",
        "a = test_df.loc[:,['meta','sentiment']]\n",
        "temp = \"\"\n",
        "test_arr = []\n",
        "test_arr_senti = []\n",
        "\n",
        "for i in range(a.shape[0]):\n",
        "  if(a.iloc[i,0]==\"meta\"):\n",
        "    #print(a.iloc[i,0])\n",
        "    test_arr.append(temp)\n",
        "    test_arr_senti.append(str(a.iloc[i,1]))\n",
        "    temp=\"\"\n",
        "  else:\n",
        "    temp+=str(a.iloc[i,0])+\" \"\n",
        "\n",
        "test_arr.append(temp)\n",
        "test_arr=test_arr[1:]\n",
        "print(test_arr[0],test_arr_senti[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RT @ UAAPconfessions Love looks good on Maddie !!! Ako lang ba yung sobrang masaya kasi may zolo sya ? Before with the past Z medyo lowkey s …  neutral\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEKcJg5ZxeJX",
        "colab_type": "code",
        "outputId": "6926db1a-08e4-4e50-a8ca-97d111f6cdb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# convert string to lower case\n",
        "train_texts = train_arr[:]\n",
        "train_texts = [s.lower() for s in train_texts]\n",
        "\n",
        "test_texts = test_arr[:]\n",
        "test_texts = [s.lower() for s in test_texts]\n",
        "\n",
        "# =======================Convert string to index================\n",
        "# Tokenizer\n",
        "tk = Tokenizer(num_words=None, char_level=True, oov_token='UNK')\n",
        "tk.fit_on_texts(train_texts)\n",
        "\n",
        "# Convert string to index\n",
        "train_sequences = tk.texts_to_sequences(train_texts)\n",
        "test_texts = tk.texts_to_sequences(test_texts)\n",
        "\n",
        "# Padding\n",
        "train_data = pad_sequences(train_sequences, maxlen=160, padding='post')\n",
        "test_data = pad_sequences(test_texts, maxlen=160, padding='post')\n",
        "\n",
        "# Convert to numpy array\n",
        "train_data = np.array(train_data, dtype='float32')\n",
        "test_data = np.array(test_data, dtype='float32')\n",
        "\n",
        "# =======================Get classes================\n",
        "train_classes_1 = train_arr_senti[:]\n",
        "train_class_list = []\n",
        "\n",
        "for i in train_classes_1:\n",
        "  if(i == \"positive\"):\n",
        "    train_class_list.append(0)\n",
        "  elif(i == \"negative\"):\n",
        "    train_class_list.append(2)\n",
        "  else:\n",
        "    train_class_list.append(1)\n",
        "\n",
        "train_class_list = np.array(train_class_list,dtype='float32')\n",
        "\n",
        "test_classes_1 = test_arr_senti[:]\n",
        "test_class_list = []\n",
        "\n",
        "for i in test_classes_1:\n",
        "  if(i == \"positive\"):\n",
        "    test_class_list.append(0)\n",
        "  elif(i == \"negative\"):\n",
        "    test_class_list.append(2)\n",
        "  else:\n",
        "    test_class_list.append(1)\n",
        "\n",
        "test_class_list = np.array(test_class_list,dtype='float32')\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "train_classes = to_categorical(train_class_list)\n",
        "test_classes = to_categorical(test_class_list)\n",
        "print(train_classes[0])\n",
        "print(test_classes[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 1.]\n",
            "[0. 1. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtIYdPb1vnQJ",
        "colab_type": "code",
        "outputId": "26794e53-da32-4166-d7bb-a8e521f799af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# =====================Char CNN=======================\n",
        "# parameter\n",
        "input_size = 160\n",
        "vocab_size = len(tk.word_index)\n",
        "print(tk.word_index)\n",
        "embedding_size = 900\n",
        "conv_layers = [[256, 3, 3],\n",
        "               [256, 3, 3],\n",
        "               [256, 3, -1],\n",
        "               [256, 3, -1],\n",
        "               [256, 3, -1],\n",
        "               [256, 3, 3]]\n",
        "\n",
        "fully_connected_layers = [1024, 1024]\n",
        "num_of_classes = 3\n",
        "dropout_p = 0.5\n",
        "optimizer = 'adadelta'\n",
        "loss = 'categorical_crossentropy'\n",
        "\n",
        "# Embedding weights\n",
        "embedding_weights = [] \n",
        "embedding_weights.append(np.zeros(vocab_size))  \n",
        "\n",
        "for char, i in tk.word_index.items():\n",
        "    onehot = np.zeros(vocab_size)\n",
        "    onehot[i - 1] = 1\n",
        "    embedding_weights.append(onehot)\n",
        "\n",
        "embedding_weights = np.array(embedding_weights)\n",
        "\n",
        "\n",
        "# Embedding layer Initialization\n",
        "embedding_layer = Embedding(vocab_size + 1,embedding_size, weights=[embedding_weights])\n",
        "\n",
        "# Model Construction\n",
        "\n",
        "# Input\n",
        "inputs = Input(shape=(input_size,), name='input', dtype='int64') \n",
        "\n",
        "# Embedding\n",
        "x = embedding_layer(inputs)\n",
        "\n",
        "# Conv\n",
        "for filter_num, filter_size, pooling_size in conv_layers:\n",
        "    x = Conv1D(filter_num, filter_size)(x)\n",
        "    x = LeakyReLU(alpha=0.05)(x)\n",
        "    if pooling_size != -1:\n",
        "        x = MaxPooling1D(pool_size=pooling_size)(x)  \n",
        "\n",
        "x = Flatten()(x)\n",
        "\n",
        "\n",
        "# Fully connected layers\n",
        "for dense_size in fully_connected_layers:\n",
        "    x = Dense(dense_size, activation='linear')(x)\n",
        "    x = LeakyReLU(alpha=0.05)(x)\n",
        "    x = Dropout(dropout_p)(x)\n",
        "\n",
        "# Output Layer\n",
        "predictions = Dense(num_of_classes, activation='softmax')(x)\n",
        "\n",
        "# Build model\n",
        "model = Model(inputs=inputs, outputs=predictions)\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])  # Adam, categorical_crossentropy\n",
        "model.summary()\n",
        "\n",
        "# Shuffle\n",
        "indices = np.arange(train_data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "x_train = train_data[indices]\n",
        "y_train = train_classes[indices]\n",
        "\n",
        "x_test = test_data\n",
        "y_test = test_classes"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'UNK': 1, ' ': 2, 'a': 3, 'i': 4, 'e': 5, 'h': 6, 'n': 7, 't': 8, 'o': 9, 'r': 10, 's': 11, 'k': 12, 'm': 13, 'l': 14, '\\t': 15, '\\n': 16, 'd': 17, 'u': 18, 'g': 19, 'p': 20, 'b': 21, 'y': 22, 'c': 23, '/': 24, '@': 25, '.': 26, 'j': 27, 'w': 28, 'f': 29, 'v': 30, '…': 31, 'z': 32, '1': 33, '_': 34, '0': 35, '4': 36, '2': 37, 'q': 38, '3': 39, 'x': 40, '9': 41, '7': 42, '5': 43, '8': 44, '6': 45, '#': 46, '!': 47, '😂': 48, '?': 49, \"'\": 50, '-': 51, '’': 52, '️': 53, '🙏': 54, '❤': 55, '🤣': 56, '😍': 57, '&': 58, ')': 59, '(': 60, '😭': 61, '*': 62, '😘': 63, '🇮': 64, '🇳': 65, '😊': 66, '🌹': 67, '💜': 68, '🎂': 69, '“': 70, '💕': 71, 'ा': 72, '😁': 73, '👏': 74, '🎉': 75, '💖': 76, '👍': 77, '|': 78, '👌': 79, '”': 80, '✌': 81, '😜': 82, '%': 83, 'र': 84, '😆': 85, '💐': 86, '🏻': 87, '+': 88, '♥': 89, '🤗': 90, '्': 91, '😎': 92, '😡': 93, '🙄': 94, '🔥': 95, '~': 96, '🤔': 97, '\\u200d': 98, '😉': 99, '💙': 100, '😠': 101, '😅': 102, '🙌': 103, '\\U0001f92a': 104, '😀': 105, 'न': 106, 'क': 107, 'म': 108, ';': 109, '🌸': 110, '💓': 111, 'ी': 112, '😋': 113, 'स': 114, '💔': 115, '☺': 116, '‘': 117, '😢': 118, '😌': 119, '—': 120, '\\U0001f970': 121, 'े': 122, '💞': 123, '💪': 124, '😝': 125, 'ह': 126, '😔': 127, 'त': 128, '💯': 129, '💗': 130, '😒': 131, '😑': 132, '😄': 133, '\\xa0': 134, '🙈': 135, '[': 136, '🚩': 137, '🌷': 138, '🎊': 139, 'ं': 140, '😇': 141, '=': 142, '😪': 143, '👇': 144, '🌺': 145, '😹': 146, 'é': 147, ']': 148, 'य': 149, '😛': 150, 'ि': 151, '😐': 152, '🏼': 153, '🙂': 154, '>': 155, '😬': 156, '🎁': 157, '😃': 158, 'ग': 159, 'प': 160, 'ब': 161, '\\U0001f929': 162, '💚': 163, '😤': 164, '😏': 165, 'á': 166, '🎈': 167, '🏽': 168, '😕': 169, '$': 170, '💏': 171, 'ا': 172, '🏆': 173, '😩': 174, '🤦': 175, '<': 176, 'द': 177, '🇵': 178, '🇰': 179, '♂': 180, 'ā': 181, 'व': 182, '\\U0001f928': 183, '♀': 184, '🙊': 185, 'ज': 186, '☹': 187, '💃': 188, 'ु': 189, 'ल': 190, '\\U0001f97a': 191, '🏾': 192, '🖕': 193, '🤧': 194, 'ो': 195, 'ू': 196, '💝': 197, '✨': 198, 'ै': 199, '\\U0001f92c': 200, '✅': 201, 'ل': 202, '💋': 203, '❣': 204, 'श': 205, '🌈': 206, '🌚': 207, 'م': 208, 'í': 209, '😶': 210, '😈': 211, 'ر': 212, '😷': 213, '👉': 214, '💛': 215, '💘': 216, '–': 217, '😣': 218, 'भ': 219, '😳': 220, 'ع': 221, '💮': 222, '🔯': 223, '👋': 224, '😨': 225, '😞': 226, '\\U0001f973': 227, 'ı': 228, 'ی': 229, '🤓': 230, '🏵': 231, '👑': 232, '😥': 233, 'ş': 234, '😚': 235, 'ᴇ': 236, 'و': 237, 'अ': 238, '🌼': 239, '😴': 240, '`': 241, '🤘': 242, '👀': 243, '\\U000e0067': 244, '🖤': 245, '⚫': 246, '😓': 247, '🙉': 248, '🎶': 249, '💥': 250, '👫': 251, 'ç': 252, '🏏': 253, 'د': 254, 'फ': 255, '🌲': 256, '్': 257, '‼': 258, '😻': 259, '🌱': 260, 'å': 261, 'ü': 262, '🐍': 263, '🤷': 264, '💫': 265, 'ध': 266, '🦋': 267, 'ट': 268, '\\U0001f932': 269, '👻': 270, '\\U0001f9e1': 271, 'ñ': 272, 'ê': 273, '🍫': 274, '🤞': 275, '😫': 276, '🙇': 277, 'ᴀ': 278, '🎼': 279, '🙃': 280, 'च': 281, '✊': 282, '💑': 283, 'ख': 284, '\\U0001f92d': 285, '👦': 286, '👈': 287, '🎵': 288, '👩': 289, '➡': 290, '✖': 291, '✔': 292, '😱': 293, 'थ': 294, '🗿': 295, '🤙': 296, 'ة': 297, 'ق': 298, 'ᴛ': 299, '🌿': 300, '🙆': 301, 'ए': 302, '•': 303, '🌵': 304, 'ర': 305, '´': 306, '⛳': 307, 'ड': 308, 'ج': 309, '☝': 310, '🇦': 311, '🏴': 312, '\\U000e0062': 313, '\\U000e007f': 314, 'ã': 315, '😯': 316, '❓': 317, '❗': 318, '🍧': 319, '₹': 320, '📄': 321, '🎓': 322, 'ɪ': 323, 'ɴ': 324, 'ᴍ': 325, '✋': 326, 'ت': 327, 'ک': 328, '🤝': 329, '👭': 330, '😟': 331, '🍰': 332, '😮': 333, 'ి': 334, 'ా': 335, '🔫': 336, '👎': 337, '🐱': 338, '🏳': 339, '😰': 340, '\\U000e0065': 341, '\\U000e006e': 342, '🖐': 343, '🌙': 344, '{': 345, '}': 346, '💩': 347, '่': 348, 'ई': 349, '^': 350, 'س': 351, '⬇': 352, '\\U0001f92f': 353, '¡': 354, '╭': 355, '╮': 356, '👨': 357, 'ɩ': 358, 'ᵒ': 359, 'ᵉ': 360, 'の': 361, '✍': 362, '𝗲': 363, '😗': 364, '🎇': 365, 'ä': 366, 'ष': 367, '👰': 368, '👸': 369, 'ʀ': 370, 'ô': 371, 'ł': 372, '📃': 373, '\\U0001f9da': 374, '👿': 375, 'इ': 376, '🇺': 377, '🇸': 378, '🍾': 379, 'ौ': 380, 'క': 381, 'ు': 382, 'స': 383, 'ం': 384, 'డ': 385, 'ప': 386, '🐷': 387, '😙': 388, '🇫': 389, '🇩': 390, '🇿': 391, '👊': 392, '🇬': 393, '💸': 394, 'आ': 395, 'ค': 396, '़': 397, '🚨': 398, '🏿': 399, '\\U0001f91f': 400, 'ے': 401, 'č': 402, 'ý': 403, '\\U0001f9d0': 404, '🔴': 405, '।': 406, '🙁': 407, '❌': 408, '👠': 409, '🎤': 410, '𝄞': 411, 'ਂ': 412, 'ن': 413, '🌟': 414, '⬆': 415, '🌻': 416, '🎀': 417, '🔝': 418, 'ˢ': 419, '🗣': 420, '\\u2066': 421, '💎': 422, 'ン': 423, 'ー': 424, '\\u200b': 425, '𝘀': 426, '🐖': 427, '😖': 428, 'ạ': 429, 'ẽ': 430, 'ó': 431, '🍨': 432, '🍬': 433, '🐯': 434, '🌝': 435, '👾': 436, 'ㅠ': 437, 'ي': 438, '►': 439, 'ण': 440, 'ᴋ': 441, 'ғ': 442, 'ᴅ': 443, '💬': 444, 'ᴏ': 445, 'ᴘ': 446, 'đ': 447, '💡': 448, '💁': 449, '🤤': 450, 'ب': 451, 'ż': 452, '🙋': 453, 'छ': 454, 'ﷺ': 455, '📷': 456, 'ँ': 457, '⃣': 458, '스': 459, 'ｓ': 460, 'మ': 461, 'న': 462, 'ద': 463, 'త': 464, 'ో': 465, 'య': 466, 'ల': 467, 'ఉ': 468, 'ష': 469, 'ृ': 470, 'ů': 471, '🇧': 472, '🇱': 473, '🌴': 474, '✈': 475, '💌': 476, '🎋': 477, 'ۃ': 478, '💀': 479, 'ꕊ': 480, '𝐡': 481, '𝐞': 482, 'ผ': 483, 'น': 484, 'ป': 485, 'ี': 486, 'อ': 487, 'บ': 488, 'ุ': 489, 'ท': 490, 'ก': 491, '\\U0001f975': 492, '🚬': 493, '🦉': 494, 'ش': 495, '👧': 496, '🌍': 497, 'ः': 498, '💅': 499, '🤒': 500, '｡': 501, '‿': 502, '◉': 503, '🍦': 504, 'ö': 505, '×': 506, '🚴': 507, '🚶': 508, '🎧': 509, '🐼': 510, '🐂': 511, '🌶': 512, 'ř': 513, '🍍': 514, '🌎': 515, '·': 516, '¯': 517, 'っ': 518, '˘': 519, '̩': 520, '🍎': 521, '🍏': 522, '♡': 523, '⃑': 524, 'լ': 525, 'ɣ': 526, 'є': 527, 'ɲ': 528, 'ਹ': 529, 'ੁ': 530, 'ਤ': 531, 'ੀ': 532, 'ਰ': 533, '🦍': 534, 'ú': 535, '🌏': 536, '®': 537, '🎬': 538, '👺': 539, '기': 540, '다': 541, '⠀': 542, '🇭': 543, '〣': 544, 'º': 545, 'ᵐ': 546, 'ʸ': 547, 'ᵍ': 548, 'ᵘ': 549, 'ᵃ': 550, 'ᶦ': 551, '\\u2069': 552, 'ダ': 553, 'ヒ': 554, 'ョ': 555, '日': 556, '限': 557, '定': 558, 'で': 559, 'す': 560, '𝗶': 561, '𝗰': 562, '🍃': 563, 'ī': 564, 'ē': 565, '🌘': 566, '⤴': 567, 'а': 568, 'î': 569, '✴': 570, '❔': 571, '⁉': 572, '➕': 573, '¿': 574, 'ğ': 575, '🤠': 576, '☪': 577, '🏖': 578, '👼': 579, 'ʟ': 580, '👥': 581, 'ɢ': 582, '💾': 583, 'ᴠ': 584, 'ᴄ': 585, 'ʏ': 586, 'ᴜ': 587, 'ʜ': 588, 'ế': 589, 'ồ': 590, 'ủ': 591, 'ề': 592, 'ố': 593, '🍂': 594, 'ئ': 595, 'ć': 596, 'ę': 597, 'ś': 598, '↑': 599, '🔷': 600, '🔶': 601, '🐸': 602, '👆': 603, '✉': 604, '🇲': 605, '🛐': 606, 'ﷻ': 607, '\\U0001f9c1': 608, '🥂': 609, '𝐹': 610, '𝒾': 611, '𝑔': 612, '𝒽': 613, '𝓉': 614, '𝒻': 615, '𝑜': 616, '𝓇': 617, '𝓊': 618, '𝓈': 619, '📝': 620, '猫': 621, 'ね': 622, 'こ': 623, 'ネ': 624, 'コ': 625, '🔞': 626, '💣': 627, 'ऑ': 628, '한': 629, '국': 630, '댄': 631, '러': 632, '시': 633, '팀': 634, '약': 635, '자': 636, '제': 637, '일': 638, '은': 639, '행': 640, 'ｕ': 641, 'ｎ': 642, 'ｅ': 643, 'ｔ': 644, '🐈': 645, '🤚': 646, 'ధ': 647, 'బ': 648, 'ే': 649, 'ఇ': 650, 'అ': 651, 'ూ': 652, 'వ': 653, 'చ': 654, '🍇': 655, 'ě': 656, 'š': 657, 'ठ': 658, '🏁': 659, '🥃': 660, '🎩': 661, '🦁': 662, '🕋': 663, '🐗': 664, 'ه': 665, '🕺': 666, '🕯': 667, '🙀': 668, 'ॉ': 669, '😲': 670, '🔚': 671, '🔨': 672, '🐒': 673, '𝐂': 674, '𝐚': 675, '𝐩': 676, '𝐭': 677, '𝐫': 678, '𝟔': 679, '𝟏': 680, '𝟐': 681, '𝐉': 682, '𝐮': 683, '𝐧': 684, '𝐖': 685, '𝐢': 686, '𝐬': 687, '︎': 688, 'า': 689, 'ไ': 690, 'แ': 691, 'ล': 692, '้': 693, 'ว': 694, 'ร': 695, 'ึ': 696, 'ง': 697, 'ข': 698, 'ณ': 699, 'ย': 700, 'ู': 701, 'ั': 702, '🤑': 703, 'ں': 704, 'ہ': 705, '★': 706, '⚔': 707, '🇷': 708, '☀': 709, '\\U0001f9f8': 710, 'ň': 711, '👐': 712, '🍀': 713, '🙅': 714, '⚪': 715, '\\U000e0073': 716, '\\U000e0063': 717, '\\U000e0074': 718, '🛍': 719, 'ò': 720, '£': 721, '€': 722, '⭐': 723, 'à': 724, '🦄': 725, '🍱': 726, '⚽': 727, '👞': 728, '\\U0001f97e': 729, '👟': 730, '😼': 731, '🌊': 732, '℅': 733, '🐥': 734, '🐿': 735, '🔈': 736, '🔪': 737, '⌚': 738, '▂': 739, '🍟': 740, '🏋': 741, '🐶': 742, '¥': 743, 'ਣ': 744, 'ਸ': 745, 'ਨ': 746, 'ਕ': 747, 'ੋ': 748, 'ਗ': 749, 'ੇ': 750, 'ਾ': 751, 'ਫ': 752, 'ਿ': 753, '―': 754, 'ì': 755, '🇨': 756, '🌳': 757, 'غ': 758, 'ط': 759, 'خ': 760, 'ز': 761, '🐮': 762, '🔁': 763, '\\U0001f9b3': 764, '📻': 765, '🌄': 766, '☔': 767, 'μ': 768, '🐓': 769, '❇': 770, '🇪': 771, 'ঈ': 772, 'দ': 773, 'ম': 774, 'ো': 775, 'ব': 776, 'া': 777, 'র': 778, 'ক': 779, '°': 780, '이': 781, '나': 782, '경': 783, '🐕': 784, '👅': 785, 'گ': 786, '🔔': 787, '🔐': 788, '🤡': 789, '🐐': 790, '\\U0001f96d': 791, '👹': 792, '📿': 793, '멀': 794, '티': 795, '뷰': 796, '와': 797, '함': 798, '께': 799, '즐': 800, '는': 801, '머': 802, '터': 803, '실': 804, '황': 805, '생': 806, '중': 807, '계': 808, '만': 809, '립': 810, '니': 811, '😵': 812, '🎟': 813, '🕌': 814, '💟': 815, 'औ': 816, '🏡': 817, '⛲': 818, 'δ': 819, 'ʰ': 820, 'ᵈ': 821, 'ʳ': 822, 'ᶜ': 823, 'ᵗ': 824, 'ᵛ': 825, 'ᵏ': 826, '😿': 827, '🤕': 828, '🎥': 829, '🤐': 830, '🔟': 831, '🎆': 832, '🎗': 833, 'は': 834, '🦅': 835, '誕': 836, '生': 837, '当': 838, '、': 839, 'イ': 840, 'ベ': 841, 'ト': 842, 'ス': 843, 'テ': 844, 'ジ': 845, 'が': 846, 'つ': 847, 'い': 848, 'に': 849, '開': 850, '放': 851, 'べ': 852, 'て': 853, 'パ': 854, 'ズ': 855, 'ル': 856, 'を': 857, 'ク': 858, 'リ': 859, 'ア': 860, 'る': 861, 'と': 862, 'ム': 863, 'ビ': 864, 'ま': 865, 'ỉ': 866, 'ư': 867, 'ờ': 868, '⇒': 869, '⛽': 870, '👶': 871, '𝗣': 872, '𝘂': 873, '𝗯': 874, '𝗹': 875, '𝗿': 876, '𝘃': 877, '𝗺': 878, '𝗮': 879, '𝗴': 880, '😦': 881, '™': 882, '📈': 883, '⚕': 884, '📣': 885, 'м': 886, 'о': 887, 'д': 888, 'к': 889, 'р': 890, 'т': 891, '🇾': 892, 'ص': 893, '🌌': 894, '👒': 895, '🥇': 896, '⚘': 897, '💍': 898, '\\U0001f974': 899, '\\U0001f92e': 900}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           (None, 160)               0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 160, 900)          810900    \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 158, 256)          691456    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 158, 256)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 52, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 50, 256)           196864    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 50, 256)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 16, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 14, 256)           196864    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 14, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 12, 256)           196864    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 12, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 10, 256)           196864    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 10, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 8, 256)            196864    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 8, 256)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 2, 256)            0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 3075      \n",
            "=================================================================\n",
            "Total params: 4,064,663\n",
            "Trainable params: 4,064,663\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4vpe4n35odC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###### To Calculate Precision, Recall, F1-Score over All Classes\n",
        "# Class1 --- Positive\n",
        "# Class2 --- Neutral\n",
        "# Class3 --- Negative\n",
        " \n",
        "import numpy as np\n",
        "from keras.callbacks import Callback\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
        "\n",
        "class Metrics(Callback):\n",
        "  def __init__(self, logs={}):\n",
        "    self.val_f1s = []\n",
        "    self.val_recalls = []\n",
        "    self.val_precisions = []\n",
        " \n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    val_predict = (np.asarray(self.model.predict(x_test))).round()\n",
        "    val_targ = y_test\n",
        "    _val_f1 = f1_score(val_targ, val_predict,average=None)\n",
        "    _val_recall = recall_score(val_targ, val_predict,average=None)\n",
        "    _val_precision = precision_score(val_targ, val_predict,average=None)\n",
        "    self.val_f1s.append(_val_f1)\n",
        "    self.val_recalls.append(_val_recall)\n",
        "    self.val_precisions.append(_val_precision)\n",
        "    print(\" — val_f1_Class1: %f — val_f1_Class2: %f — val_f1_Class3: %f — val_precision_Class1: %f — val_precision_Class2: %f — val_precision_Class3: %f — val_recall_Class1 %f — val_recall_Class2 %f — val_recall_Class3 %f\" %(_val_f1[0], _val_f1[1], _val_f1[2], _val_precision[0], _val_precision[1], _val_precision[2], _val_recall[0], _val_recall[1], _val_recall[2]))\n",
        "    return\n",
        " \n",
        "metrics = Metrics()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvEWOzrpn3c7",
        "colab_type": "code",
        "outputId": "c6f66b99-ec14-472f-b68e-62ee195a70ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x_train, y_train,validation_data=(x_test, y_test),batch_size=128,epochs=30,verbose=1,callbacks=[metrics])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 13524 samples, validate on 1869 samples\n",
            "Epoch 1/30\n",
            "13524/13524 [==============================] - 3s 216us/step - loss: 0.1299 - acc: 0.9582 - val_loss: 2.3657 - val_acc: 0.4981\n",
            " — val_f1_Class1: 0.489051 — val_f1_Class2: 0.474185 — val_f1_Class3: 0.534378 — val_precision_Class1: 0.521401 — val_precision_Class2: 0.486072 — val_precision_Class3: 0.498377 — val_recall_Class1 0.460481 — val_recall_Class2 0.462865 — val_recall_Class3 0.575985\n",
            "Epoch 2/30\n",
            "13524/13524 [==============================] - 3s 216us/step - loss: 0.0929 - acc: 0.9719 - val_loss: 2.4672 - val_acc: 0.5099\n",
            " — val_f1_Class1: 0.485876 — val_f1_Class2: 0.497087 — val_f1_Class3: 0.546763 — val_precision_Class1: 0.537500 — val_precision_Class2: 0.485461 — val_precision_Class3: 0.525043 — val_recall_Class1 0.443299 — val_recall_Class2 0.509284 — val_recall_Class3 0.570356\n",
            "Epoch 3/30\n",
            "13524/13524 [==============================] - 3s 216us/step - loss: 0.1057 - acc: 0.9670 - val_loss: 2.5476 - val_acc: 0.4810\n",
            " — val_f1_Class1: 0.327456 — val_f1_Class2: 0.524315 — val_f1_Class3: 0.520140 — val_precision_Class1: 0.613208 — val_precision_Class2: 0.453140 — val_precision_Class3: 0.487685 — val_recall_Class1 0.223368 — val_recall_Class2 0.622016 — val_recall_Class3 0.557223\n",
            "Epoch 4/30\n",
            "13524/13524 [==============================] - 3s 216us/step - loss: 0.0821 - acc: 0.9755 - val_loss: 2.7420 - val_acc: 0.5013\n",
            " — val_f1_Class1: 0.484192 — val_f1_Class2: 0.538762 — val_f1_Class3: 0.439320 — val_precision_Class1: 0.510476 — val_precision_Class2: 0.464870 — val_precision_Class3: 0.621993 — val_recall_Class1 0.460481 — val_recall_Class2 0.640584 — val_recall_Class3 0.339587\n",
            "Epoch 5/30\n",
            "13524/13524 [==============================] - 3s 216us/step - loss: 0.0786 - acc: 0.9756 - val_loss: 2.6841 - val_acc: 0.5078\n",
            " — val_f1_Class1: 0.448770 — val_f1_Class2: 0.534463 — val_f1_Class3: 0.512665 — val_precision_Class1: 0.555838 — val_precision_Class2: 0.465551 — val_precision_Class3: 0.557269 — val_recall_Class1 0.376289 — val_recall_Class2 0.627321 — val_recall_Class3 0.474672\n",
            "Epoch 6/30\n",
            "13524/13524 [==============================] - 3s 217us/step - loss: 0.0761 - acc: 0.9759 - val_loss: 2.6552 - val_acc: 0.5056\n",
            " — val_f1_Class1: 0.449848 — val_f1_Class2: 0.518430 — val_f1_Class3: 0.531429 — val_precision_Class1: 0.548148 — val_precision_Class2: 0.469828 — val_precision_Class3: 0.539652 — val_recall_Class1 0.381443 — val_recall_Class2 0.578249 — val_recall_Class3 0.523452\n",
            "Epoch 7/30\n",
            "13524/13524 [==============================] - 3s 216us/step - loss: 0.0783 - acc: 0.9766 - val_loss: 2.6792 - val_acc: 0.5062\n",
            " — val_f1_Class1: 0.483012 — val_f1_Class2: 0.493256 — val_f1_Class3: 0.542593 — val_precision_Class1: 0.518738 — val_precision_Class2: 0.478207 — val_precision_Class3: 0.535649 — val_recall_Class1 0.451890 — val_recall_Class2 0.509284 — val_recall_Class3 0.549719\n",
            "Epoch 8/30\n",
            "13524/13524 [==============================] - 3s 216us/step - loss: 0.0508 - acc: 0.9849 - val_loss: 2.8753 - val_acc: 0.5062\n",
            " — val_f1_Class1: 0.460039 — val_f1_Class2: 0.523896 — val_f1_Class3: 0.522402 — val_precision_Class1: 0.531532 — val_precision_Class2: 0.481646 — val_precision_Class3: 0.531008 — val_recall_Class1 0.405498 — val_recall_Class2 0.574271 — val_recall_Class3 0.514071\n",
            "Epoch 9/30\n",
            "13524/13524 [==============================] - 3s 216us/step - loss: 0.0539 - acc: 0.9834 - val_loss: 3.1825 - val_acc: 0.5104\n",
            " — val_f1_Class1: 0.531665 — val_f1_Class2: 0.498044 — val_f1_Class3: 0.493989 — val_precision_Class1: 0.487805 — val_precision_Class2: 0.489744 — val_precision_Class3: 0.591623 — val_recall_Class1 0.584192 — val_recall_Class2 0.506631 — val_recall_Class3 0.424015\n",
            "Epoch 10/30\n",
            "13524/13524 [==============================] - 3s 216us/step - loss: 0.0705 - acc: 0.9775 - val_loss: 3.0747 - val_acc: 0.4997\n",
            " — val_f1_Class1: 0.520286 — val_f1_Class2: 0.479578 — val_f1_Class3: 0.503688 — val_precision_Class1: 0.484444 — val_precision_Class2: 0.476440 — val_precision_Class3: 0.574519 — val_recall_Class1 0.561856 — val_recall_Class2 0.482759 — val_recall_Class3 0.448405\n",
            "Epoch 11/30\n",
            "13524/13524 [==============================] - 3s 216us/step - loss: 0.0650 - acc: 0.9790 - val_loss: 2.7724 - val_acc: 0.5008\n",
            " — val_f1_Class1: 0.468872 — val_f1_Class2: 0.531963 — val_f1_Class3: 0.480423 — val_precision_Class1: 0.540359 — val_precision_Class2: 0.466934 — val_precision_Class3: 0.550971 — val_recall_Class1 0.414089 — val_recall_Class2 0.618037 — val_recall_Class3 0.425891\n",
            "Epoch 12/30\n",
            "13524/13524 [==============================] - 3s 216us/step - loss: 0.0359 - acc: 0.9885 - val_loss: 3.0410 - val_acc: 0.5072\n",
            " — val_f1_Class1: 0.500000 — val_f1_Class2: 0.514804 — val_f1_Class3: 0.497942 — val_precision_Class1: 0.530888 — val_precision_Class2: 0.472808 — val_precision_Class3: 0.551253 — val_recall_Class1 0.472509 — val_recall_Class2 0.564987 — val_recall_Class3 0.454034\n",
            "Epoch 13/30\n",
            "13524/13524 [==============================] - 3s 216us/step - loss: 0.0507 - acc: 0.9844 - val_loss: 2.9622 - val_acc: 0.4960\n",
            " — val_f1_Class1: 0.426943 — val_f1_Class2: 0.512760 — val_f1_Class3: 0.527881 — val_precision_Class1: 0.537859 — val_precision_Class2: 0.464017 — val_precision_Class3: 0.523020 — val_recall_Class1 0.353952 — val_recall_Class2 0.572944 — val_recall_Class3 0.532833\n",
            "Epoch 14/30\n",
            "13524/13524 [==============================] - 3s 217us/step - loss: 0.0510 - acc: 0.9826 - val_loss: 3.1183 - val_acc: 0.5067\n",
            " — val_f1_Class1: 0.510186 — val_f1_Class2: 0.527059 — val_f1_Class3: 0.458613 — val_precision_Class1: 0.526508 — val_precision_Class2: 0.473573 — val_precision_Class3: 0.567867 — val_recall_Class1 0.494845 — val_recall_Class2 0.594164 — val_recall_Class3 0.384615\n",
            "Epoch 15/30\n",
            "13524/13524 [==============================] - 3s 217us/step - loss: 0.0506 - acc: 0.9841 - val_loss: 3.0014 - val_acc: 0.5142\n",
            " — val_f1_Class1: 0.538763 — val_f1_Class2: 0.480556 — val_f1_Class3: 0.529353 — val_precision_Class1: 0.494964 — val_precision_Class2: 0.504373 — val_precision_Class3: 0.563559 — val_recall_Class1 0.591065 — val_recall_Class2 0.458886 — val_recall_Class3 0.499062\n",
            "Epoch 16/30\n",
            "13524/13524 [==============================] - 3s 215us/step - loss: 0.0397 - acc: 0.9861 - val_loss: 3.2963 - val_acc: 0.5110\n",
            " — val_f1_Class1: 0.498664 — val_f1_Class2: 0.500968 — val_f1_Class3: 0.537143 — val_precision_Class1: 0.517560 — val_precision_Class2: 0.488050 — val_precision_Class3: 0.545455 — val_recall_Class1 0.481100 — val_recall_Class2 0.514589 — val_recall_Class3 0.529081\n",
            "Epoch 17/30\n",
            "13524/13524 [==============================] - 3s 216us/step - loss: 0.0526 - acc: 0.9839 - val_loss: 2.8957 - val_acc: 0.4965\n",
            " — val_f1_Class1: 0.481448 — val_f1_Class2: 0.497189 — val_f1_Class3: 0.516385 — val_precision_Class1: 0.508604 — val_precision_Class2: 0.469894 — val_precision_Class3: 0.548523 — val_recall_Class1 0.457045 — val_recall_Class2 0.527851 — val_recall_Class3 0.487805\n",
            "Epoch 18/30\n",
            "13524/13524 [==============================] - 3s 216us/step - loss: 0.0323 - acc: 0.9905 - val_loss: 3.5278 - val_acc: 0.5062\n",
            " — val_f1_Class1: 0.483599 — val_f1_Class2: 0.509926 — val_f1_Class3: 0.516190 — val_precision_Class1: 0.531959 — val_precision_Class2: 0.479021 — val_precision_Class3: 0.524178 — val_recall_Class1 0.443299 — val_recall_Class2 0.545093 — val_recall_Class3 0.508443\n",
            "Epoch 19/30\n",
            "13524/13524 [==============================] - 3s 216us/step - loss: 0.0295 - acc: 0.9909 - val_loss: 3.6120 - val_acc: 0.5083\n",
            " — val_f1_Class1: 0.505687 — val_f1_Class2: 0.502231 — val_f1_Class3: 0.519174 — val_precision_Class1: 0.515152 — val_precision_Class2: 0.483436 — val_precision_Class3: 0.545455 — val_recall_Class1 0.496564 — val_recall_Class2 0.522546 — val_recall_Class3 0.495310\n",
            "Epoch 20/30\n",
            "13524/13524 [==============================] - 3s 217us/step - loss: 0.0459 - acc: 0.9858 - val_loss: 3.2878 - val_acc: 0.5062\n",
            " — val_f1_Class1: 0.492593 — val_f1_Class2: 0.527473 — val_f1_Class3: 0.477644 — val_precision_Class1: 0.534137 — val_precision_Class2: 0.467692 — val_precision_Class3: 0.570312 — val_recall_Class1 0.457045 — val_recall_Class2 0.604775 — val_recall_Class3 0.410882\n",
            "Epoch 21/30\n",
            "13524/13524 [==============================] - 3s 217us/step - loss: 0.0244 - acc: 0.9911 - val_loss: 3.6776 - val_acc: 0.4896\n",
            " — val_f1_Class1: 0.512490 — val_f1_Class2: 0.508128 — val_f1_Class3: 0.419632 — val_precision_Class1: 0.482549 — val_precision_Class2: 0.465270 — val_precision_Class3: 0.606383 — val_recall_Class1 0.546392 — val_recall_Class2 0.559682 — val_recall_Class3 0.320826\n",
            "Epoch 22/30\n",
            "13524/13524 [==============================] - 3s 215us/step - loss: 0.0536 - acc: 0.9828 - val_loss: 3.0655 - val_acc: 0.5008\n",
            " — val_f1_Class1: 0.448731 — val_f1_Class2: 0.509091 — val_f1_Class3: 0.534070 — val_precision_Class1: 0.548387 — val_precision_Class2: 0.468750 — val_precision_Class3: 0.524412 — val_recall_Class1 0.379725 — val_recall_Class2 0.557029 — val_recall_Class3 0.544090\n",
            "Epoch 23/30\n",
            "13524/13524 [==============================] - 3s 216us/step - loss: 0.0232 - acc: 0.9919 - val_loss: 3.6654 - val_acc: 0.5179\n",
            " — val_f1_Class1: 0.530541 — val_f1_Class2: 0.510450 — val_f1_Class3: 0.514457 — val_precision_Class1: 0.539007 — val_precision_Class2: 0.488485 — val_precision_Class3: 0.548936 — val_recall_Class1 0.522337 — val_recall_Class2 0.534483 — val_recall_Class3 0.484053\n",
            "Epoch 24/30\n",
            "10368/13524 [=====================>........] - ETA: 0s - loss: 0.0254 - acc: 0.9904"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-8d108413dda3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUXQheLVNDyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}