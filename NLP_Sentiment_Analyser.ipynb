{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Sentiment_Analyser.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOXWmn_wZrGV",
        "colab_type": "code",
        "outputId": "f20bf814-e86c-43b0-f241-bdece3b796a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import keras.callbacks\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dense, Input, Dropout, MaxPooling1D, Conv1D, GlobalMaxPool1D\n",
        "from keras.layers import LSTM, Lambda, concatenate, TimeDistributed, Bidirectional"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7V7qgfOxIdD",
        "colab_type": "code",
        "outputId": "7a808937-cc22-4c95-a864-d2cedbc12913",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0NWLIa5vbAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from keras.layers import Input, Embedding, Activation, Flatten, Dense\n",
        "from keras.layers import Conv1D, MaxPooling1D, Dropout\n",
        "from keras.models import Model\n",
        "from keras.layers import LeakyReLU\n",
        "\n",
        "train_data_source = '/content/drive/My Drive/nlp_assignment_3/train.csv'\n",
        "test_data_source = '/content/drive/My Drive/nlp_assignment_3/test.csv'\n",
        "\n",
        "train_df = pd.read_csv(train_data_source, delimiter=\"\\t\")\n",
        "test_df = pd.read_csv(test_data_source, delimiter=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rmjp_bmexlI0",
        "colab_type": "code",
        "outputId": "512f2ded-21f6-42c1-f84e-9740f1a4ea20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>meta</th>\n",
              "      <th>uid</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>meta</td>\n",
              "      <td>3</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@</td>\n",
              "      <td>O</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AdilNisarButt</td>\n",
              "      <td>Hin</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pakistan</td>\n",
              "      <td>Hin</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ka</td>\n",
              "      <td>Hin</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            meta  uid sentiment\n",
              "0           meta    3  negative\n",
              "1              @    O       NaN\n",
              "2  AdilNisarButt  Hin       NaN\n",
              "3       pakistan  Hin       NaN\n",
              "4             ka  Hin       NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nglFKD6gPzuK",
        "colab_type": "code",
        "outputId": "2b02d697-ab8c-4289-db76-cbd7dd57206a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>meta</th>\n",
              "      <th>uid</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>meta</td>\n",
              "      <td>8</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RT</td>\n",
              "      <td>Eng</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@</td>\n",
              "      <td>O</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>UAAPconfessions</td>\n",
              "      <td>Eng</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Love</td>\n",
              "      <td>Eng</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              meta  uid sentiment\n",
              "0             meta    8   neutral\n",
              "1               RT  Eng       NaN\n",
              "2                @    O       NaN\n",
              "3  UAAPconfessions  Eng       NaN\n",
              "4             Love  Eng       NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Pm8gQh2LaF4",
        "colab_type": "code",
        "outputId": "2c3c23ad-18b2-417a-f97e-d285d0262d1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "string = \"\"\n",
        "a = train_df.loc[:,['meta','sentiment']]\n",
        "temp = \"\"\n",
        "train_arr = []\n",
        "train_arr_senti = []\n",
        "\n",
        "for i in range(a.shape[0]):\n",
        "  if(a.iloc[i,0]==\"meta\"):\n",
        "    #print(a.iloc[i,0])\n",
        "    train_arr.append(temp)\n",
        "    train_arr_senti.append(str(a.iloc[i,1]))\n",
        "    temp=\"\"\n",
        "  else:\n",
        "    temp+=str(a.iloc[i,0])+\" \"\n",
        "\n",
        "train_arr.append(temp)\n",
        "train_arr=train_arr[1:]\n",
        "print(train_arr[0],train_arr_senti[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@ AdilNisarButt pakistan ka ghra tauq he Pakistan Israel ko tasleem nahein kerta Isko Palestine kehta he - OCCUPIED PALESTINE  negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_7YZXfvPws6",
        "colab_type": "code",
        "outputId": "9c085fe9-f299-41fb-c578-b789f438868d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "string = \"\"\n",
        "a = test_df.loc[:,['meta','sentiment']]\n",
        "temp = \"\"\n",
        "test_arr = []\n",
        "test_arr_senti = []\n",
        "\n",
        "for i in range(a.shape[0]):\n",
        "  if(a.iloc[i,0]==\"meta\"):\n",
        "    #print(a.iloc[i,0])\n",
        "    test_arr.append(temp)\n",
        "    test_arr_senti.append(str(a.iloc[i,1]))\n",
        "    temp=\"\"\n",
        "  else:\n",
        "    temp+=str(a.iloc[i,0])+\" \"\n",
        "\n",
        "test_arr.append(temp)\n",
        "test_arr=test_arr[1:]\n",
        "print(test_arr[0],test_arr_senti[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RT @ UAAPconfessions Love looks good on Maddie !!! Ako lang ba yung sobrang masaya kasi may zolo sya ? Before with the past Z medyo lowkey s …  neutral\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEKcJg5ZxeJX",
        "colab_type": "code",
        "outputId": "6926db1a-08e4-4e50-a8ca-97d111f6cdb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# convert string to lower case\n",
        "train_texts = train_arr[:]\n",
        "train_texts = [s.lower() for s in train_texts]\n",
        "\n",
        "test_texts = test_arr[:]\n",
        "test_texts = [s.lower() for s in test_texts]\n",
        "\n",
        "# =======================Convert string to index================\n",
        "# Tokenizer\n",
        "tk = Tokenizer(num_words=None, char_level=True, oov_token='UNK')\n",
        "tk.fit_on_texts(train_texts)\n",
        "\n",
        "# Convert string to index\n",
        "train_sequences = tk.texts_to_sequences(train_texts)\n",
        "test_texts = tk.texts_to_sequences(test_texts)\n",
        "\n",
        "# Padding\n",
        "train_data = pad_sequences(train_sequences, maxlen=160, padding='post')\n",
        "test_data = pad_sequences(test_texts, maxlen=160, padding='post')\n",
        "\n",
        "# Convert to numpy array\n",
        "train_data = np.array(train_data, dtype='float32')\n",
        "test_data = np.array(test_data, dtype='float32')\n",
        "\n",
        "# =======================Get classes================\n",
        "train_classes_1 = train_arr_senti[:]\n",
        "train_class_list = []\n",
        "\n",
        "for i in train_classes_1:\n",
        "  if(i == \"positive\"):\n",
        "    train_class_list.append(0)\n",
        "  elif(i == \"negative\"):\n",
        "    train_class_list.append(2)\n",
        "  else:\n",
        "    train_class_list.append(1)\n",
        "\n",
        "train_class_list = np.array(train_class_list,dtype='float32')\n",
        "\n",
        "test_classes_1 = test_arr_senti[:]\n",
        "test_class_list = []\n",
        "\n",
        "for i in test_classes_1:\n",
        "  if(i == \"positive\"):\n",
        "    test_class_list.append(0)\n",
        "  elif(i == \"negative\"):\n",
        "    test_class_list.append(2)\n",
        "  else:\n",
        "    test_class_list.append(1)\n",
        "\n",
        "test_class_list = np.array(test_class_list,dtype='float32')\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "train_classes = to_categorical(train_class_list)\n",
        "test_classes = to_categorical(test_class_list)\n",
        "print(train_classes[0])\n",
        "print(test_classes[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 1.]\n",
            "[0. 1. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wD3A3ShRy8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import GRU,LSTM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtIYdPb1vnQJ",
        "colab_type": "code",
        "outputId": "0c985001-a8c1-4052-e9f8-8eb834fb443a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# =====================Char CNN=======================\n",
        "# parameter\n",
        "input_size = 160\n",
        "vocab_size = len(tk.word_index)\n",
        "print(tk.word_index)\n",
        "embedding_size = 900\n",
        "conv_layers = [[256, 3, 3],\n",
        "               [256, 3, 3],\n",
        "               [256, 3, -1],\n",
        "               [256, 3, -1],\n",
        "               [256, 3, -1],\n",
        "               [256, 3, 3]]\n",
        "\n",
        "fully_connected_layers = [1024, 1024]\n",
        "num_of_classes = 3\n",
        "dropout_p = 0.5\n",
        "optimizer = 'adadelta'\n",
        "loss = 'categorical_crossentropy'\n",
        "\n",
        "# Embedding weights\n",
        "embedding_weights = [] \n",
        "embedding_weights.append(np.zeros(vocab_size))  \n",
        "\n",
        "for char, i in tk.word_index.items():\n",
        "    onehot = np.zeros(vocab_size)\n",
        "    onehot[i - 1] = 1\n",
        "    embedding_weights.append(onehot)\n",
        "\n",
        "embedding_weights = np.array(embedding_weights)\n",
        "\n",
        "\n",
        "# Embedding layer Initialization\n",
        "embedding_layer = Embedding(vocab_size + 1,embedding_size, weights=[embedding_weights])\n",
        "\n",
        "# Model Construction\n",
        "\n",
        "# Input\n",
        "inputs = Input(shape=(input_size,), name='input', dtype='int64') \n",
        "\n",
        "# Embedding\n",
        "x = embedding_layer(inputs)\n",
        "\n",
        "# Conv\n",
        "for filter_num, filter_size, pooling_size in conv_layers:\n",
        "    x = Conv1D(filter_num, filter_size)(x)\n",
        "    x = LeakyReLU(alpha=0.05)(x)\n",
        "    if pooling_size != -1:\n",
        "        x = MaxPooling1D(pool_size=pooling_size)(x)  \n",
        "\n",
        "x = LSTM(300, dropout = 0.4, recurrent_dropout = 0.4)(x)\n",
        "\n",
        "# x = Flatten()(x)\n",
        "\n",
        "# Fully connected layers\n",
        "for dense_size in fully_connected_layers:\n",
        "    x = Dense(dense_size, activation='linear')(x)\n",
        "    x = LeakyReLU(alpha=0.05)(x)\n",
        "    x = Dropout(dropout_p)(x)\n",
        "\n",
        "# Output Layer\n",
        "predictions = Dense(num_of_classes, activation='softmax')(x)\n",
        "\n",
        "# Build model\n",
        "model = Model(inputs=inputs, outputs=predictions)\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])  # Adam, categorical_crossentropy\n",
        "model.summary()\n",
        "\n",
        "# Shuffle\n",
        "indices = np.arange(train_data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "x_train = train_data[indices]\n",
        "y_train = train_classes[indices]\n",
        "\n",
        "x_test = test_data\n",
        "y_test = test_classes"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'UNK': 1, ' ': 2, 'a': 3, 'i': 4, 'e': 5, 'h': 6, 'n': 7, 't': 8, 'o': 9, 'r': 10, 's': 11, 'k': 12, 'm': 13, 'l': 14, '\\t': 15, '\\n': 16, 'd': 17, 'u': 18, 'g': 19, 'p': 20, 'b': 21, 'y': 22, 'c': 23, '/': 24, '@': 25, '.': 26, 'j': 27, 'w': 28, 'f': 29, 'v': 30, '…': 31, 'z': 32, '1': 33, '_': 34, '0': 35, '4': 36, '2': 37, 'q': 38, '3': 39, 'x': 40, '9': 41, '7': 42, '5': 43, '8': 44, '6': 45, '#': 46, '!': 47, '😂': 48, '?': 49, \"'\": 50, '-': 51, '’': 52, '️': 53, '🙏': 54, '❤': 55, '🤣': 56, '😍': 57, '&': 58, ')': 59, '(': 60, '😭': 61, '*': 62, '😘': 63, '🇮': 64, '🇳': 65, '😊': 66, '🌹': 67, '💜': 68, '🎂': 69, '“': 70, '💕': 71, 'ा': 72, '😁': 73, '👏': 74, '🎉': 75, '💖': 76, '👍': 77, '|': 78, '👌': 79, '”': 80, '✌': 81, '😜': 82, '%': 83, 'र': 84, '😆': 85, '💐': 86, '🏻': 87, '+': 88, '♥': 89, '🤗': 90, '्': 91, '😎': 92, '😡': 93, '🙄': 94, '🔥': 95, '~': 96, '🤔': 97, '\\u200d': 98, '😉': 99, '💙': 100, '😠': 101, '😅': 102, '🙌': 103, '\\U0001f92a': 104, '😀': 105, 'न': 106, 'क': 107, 'म': 108, ';': 109, '🌸': 110, '💓': 111, 'ी': 112, '😋': 113, 'स': 114, '💔': 115, '☺': 116, '‘': 117, '😢': 118, '😌': 119, '—': 120, '\\U0001f970': 121, 'े': 122, '💞': 123, '💪': 124, '😝': 125, 'ह': 126, '😔': 127, 'त': 128, '💯': 129, '💗': 130, '😒': 131, '😑': 132, '😄': 133, '\\xa0': 134, '🙈': 135, '[': 136, '🚩': 137, '🌷': 138, '🎊': 139, 'ं': 140, '😇': 141, '=': 142, '😪': 143, '👇': 144, '🌺': 145, '😹': 146, 'é': 147, ']': 148, 'य': 149, '😛': 150, 'ि': 151, '😐': 152, '🏼': 153, '🙂': 154, '>': 155, '😬': 156, '🎁': 157, '😃': 158, 'ग': 159, 'प': 160, 'ब': 161, '\\U0001f929': 162, '💚': 163, '😤': 164, '😏': 165, 'á': 166, '🎈': 167, '🏽': 168, '😕': 169, '$': 170, '💏': 171, 'ا': 172, '🏆': 173, '😩': 174, '🤦': 175, '<': 176, 'द': 177, '🇵': 178, '🇰': 179, '♂': 180, 'ā': 181, 'व': 182, '\\U0001f928': 183, '♀': 184, '🙊': 185, 'ज': 186, '☹': 187, '💃': 188, 'ु': 189, 'ल': 190, '\\U0001f97a': 191, '🏾': 192, '🖕': 193, '🤧': 194, 'ो': 195, 'ू': 196, '💝': 197, '✨': 198, 'ै': 199, '\\U0001f92c': 200, '✅': 201, 'ل': 202, '💋': 203, '❣': 204, 'श': 205, '🌈': 206, '🌚': 207, 'م': 208, 'í': 209, '😶': 210, '😈': 211, 'ر': 212, '😷': 213, '👉': 214, '💛': 215, '💘': 216, '–': 217, '😣': 218, 'भ': 219, '😳': 220, 'ع': 221, '💮': 222, '🔯': 223, '👋': 224, '😨': 225, '😞': 226, '\\U0001f973': 227, 'ı': 228, 'ی': 229, '🤓': 230, '🏵': 231, '👑': 232, '😥': 233, 'ş': 234, '😚': 235, 'ᴇ': 236, 'و': 237, 'अ': 238, '🌼': 239, '😴': 240, '`': 241, '🤘': 242, '👀': 243, '\\U000e0067': 244, '🖤': 245, '⚫': 246, '😓': 247, '🙉': 248, '🎶': 249, '💥': 250, '👫': 251, 'ç': 252, '🏏': 253, 'د': 254, 'फ': 255, '🌲': 256, '్': 257, '‼': 258, '😻': 259, '🌱': 260, 'å': 261, 'ü': 262, '🐍': 263, '🤷': 264, '💫': 265, 'ध': 266, '🦋': 267, 'ट': 268, '\\U0001f932': 269, '👻': 270, '\\U0001f9e1': 271, 'ñ': 272, 'ê': 273, '🍫': 274, '🤞': 275, '😫': 276, '🙇': 277, 'ᴀ': 278, '🎼': 279, '🙃': 280, 'च': 281, '✊': 282, '💑': 283, 'ख': 284, '\\U0001f92d': 285, '👦': 286, '👈': 287, '🎵': 288, '👩': 289, '➡': 290, '✖': 291, '✔': 292, '😱': 293, 'थ': 294, '🗿': 295, '🤙': 296, 'ة': 297, 'ق': 298, 'ᴛ': 299, '🌿': 300, '🙆': 301, 'ए': 302, '•': 303, '🌵': 304, 'ర': 305, '´': 306, '⛳': 307, 'ड': 308, 'ج': 309, '☝': 310, '🇦': 311, '🏴': 312, '\\U000e0062': 313, '\\U000e007f': 314, 'ã': 315, '😯': 316, '❓': 317, '❗': 318, '🍧': 319, '₹': 320, '📄': 321, '🎓': 322, 'ɪ': 323, 'ɴ': 324, 'ᴍ': 325, '✋': 326, 'ت': 327, 'ک': 328, '🤝': 329, '👭': 330, '😟': 331, '🍰': 332, '😮': 333, 'ి': 334, 'ా': 335, '🔫': 336, '👎': 337, '🐱': 338, '🏳': 339, '😰': 340, '\\U000e0065': 341, '\\U000e006e': 342, '🖐': 343, '🌙': 344, '{': 345, '}': 346, '💩': 347, '่': 348, 'ई': 349, '^': 350, 'س': 351, '⬇': 352, '\\U0001f92f': 353, '¡': 354, '╭': 355, '╮': 356, '👨': 357, 'ɩ': 358, 'ᵒ': 359, 'ᵉ': 360, 'の': 361, '✍': 362, '𝗲': 363, '😗': 364, '🎇': 365, 'ä': 366, 'ष': 367, '👰': 368, '👸': 369, 'ʀ': 370, 'ô': 371, 'ł': 372, '📃': 373, '\\U0001f9da': 374, '👿': 375, 'इ': 376, '🇺': 377, '🇸': 378, '🍾': 379, 'ौ': 380, 'క': 381, 'ు': 382, 'స': 383, 'ం': 384, 'డ': 385, 'ప': 386, '🐷': 387, '😙': 388, '🇫': 389, '🇩': 390, '🇿': 391, '👊': 392, '🇬': 393, '💸': 394, 'आ': 395, 'ค': 396, '़': 397, '🚨': 398, '🏿': 399, '\\U0001f91f': 400, 'ے': 401, 'č': 402, 'ý': 403, '\\U0001f9d0': 404, '🔴': 405, '।': 406, '🙁': 407, '❌': 408, '👠': 409, '🎤': 410, '𝄞': 411, 'ਂ': 412, 'ن': 413, '🌟': 414, '⬆': 415, '🌻': 416, '🎀': 417, '🔝': 418, 'ˢ': 419, '🗣': 420, '\\u2066': 421, '💎': 422, 'ン': 423, 'ー': 424, '\\u200b': 425, '𝘀': 426, '🐖': 427, '😖': 428, 'ạ': 429, 'ẽ': 430, 'ó': 431, '🍨': 432, '🍬': 433, '🐯': 434, '🌝': 435, '👾': 436, 'ㅠ': 437, 'ي': 438, '►': 439, 'ण': 440, 'ᴋ': 441, 'ғ': 442, 'ᴅ': 443, '💬': 444, 'ᴏ': 445, 'ᴘ': 446, 'đ': 447, '💡': 448, '💁': 449, '🤤': 450, 'ب': 451, 'ż': 452, '🙋': 453, 'छ': 454, 'ﷺ': 455, '📷': 456, 'ँ': 457, '⃣': 458, '스': 459, 'ｓ': 460, 'మ': 461, 'న': 462, 'ద': 463, 'త': 464, 'ో': 465, 'య': 466, 'ల': 467, 'ఉ': 468, 'ష': 469, 'ृ': 470, 'ů': 471, '🇧': 472, '🇱': 473, '🌴': 474, '✈': 475, '💌': 476, '🎋': 477, 'ۃ': 478, '💀': 479, 'ꕊ': 480, '𝐡': 481, '𝐞': 482, 'ผ': 483, 'น': 484, 'ป': 485, 'ี': 486, 'อ': 487, 'บ': 488, 'ุ': 489, 'ท': 490, 'ก': 491, '\\U0001f975': 492, '🚬': 493, '🦉': 494, 'ش': 495, '👧': 496, '🌍': 497, 'ः': 498, '💅': 499, '🤒': 500, '｡': 501, '‿': 502, '◉': 503, '🍦': 504, 'ö': 505, '×': 506, '🚴': 507, '🚶': 508, '🎧': 509, '🐼': 510, '🐂': 511, '🌶': 512, 'ř': 513, '🍍': 514, '🌎': 515, '·': 516, '¯': 517, 'っ': 518, '˘': 519, '̩': 520, '🍎': 521, '🍏': 522, '♡': 523, '⃑': 524, 'լ': 525, 'ɣ': 526, 'є': 527, 'ɲ': 528, 'ਹ': 529, 'ੁ': 530, 'ਤ': 531, 'ੀ': 532, 'ਰ': 533, '🦍': 534, 'ú': 535, '🌏': 536, '®': 537, '🎬': 538, '👺': 539, '기': 540, '다': 541, '⠀': 542, '🇭': 543, '〣': 544, 'º': 545, 'ᵐ': 546, 'ʸ': 547, 'ᵍ': 548, 'ᵘ': 549, 'ᵃ': 550, 'ᶦ': 551, '\\u2069': 552, 'ダ': 553, 'ヒ': 554, 'ョ': 555, '日': 556, '限': 557, '定': 558, 'で': 559, 'す': 560, '𝗶': 561, '𝗰': 562, '🍃': 563, 'ī': 564, 'ē': 565, '🌘': 566, '⤴': 567, 'а': 568, 'î': 569, '✴': 570, '❔': 571, '⁉': 572, '➕': 573, '¿': 574, 'ğ': 575, '🤠': 576, '☪': 577, '🏖': 578, '👼': 579, 'ʟ': 580, '👥': 581, 'ɢ': 582, '💾': 583, 'ᴠ': 584, 'ᴄ': 585, 'ʏ': 586, 'ᴜ': 587, 'ʜ': 588, 'ế': 589, 'ồ': 590, 'ủ': 591, 'ề': 592, 'ố': 593, '🍂': 594, 'ئ': 595, 'ć': 596, 'ę': 597, 'ś': 598, '↑': 599, '🔷': 600, '🔶': 601, '🐸': 602, '👆': 603, '✉': 604, '🇲': 605, '🛐': 606, 'ﷻ': 607, '\\U0001f9c1': 608, '🥂': 609, '𝐹': 610, '𝒾': 611, '𝑔': 612, '𝒽': 613, '𝓉': 614, '𝒻': 615, '𝑜': 616, '𝓇': 617, '𝓊': 618, '𝓈': 619, '📝': 620, '猫': 621, 'ね': 622, 'こ': 623, 'ネ': 624, 'コ': 625, '🔞': 626, '💣': 627, 'ऑ': 628, '한': 629, '국': 630, '댄': 631, '러': 632, '시': 633, '팀': 634, '약': 635, '자': 636, '제': 637, '일': 638, '은': 639, '행': 640, 'ｕ': 641, 'ｎ': 642, 'ｅ': 643, 'ｔ': 644, '🐈': 645, '🤚': 646, 'ధ': 647, 'బ': 648, 'ే': 649, 'ఇ': 650, 'అ': 651, 'ూ': 652, 'వ': 653, 'చ': 654, '🍇': 655, 'ě': 656, 'š': 657, 'ठ': 658, '🏁': 659, '🥃': 660, '🎩': 661, '🦁': 662, '🕋': 663, '🐗': 664, 'ه': 665, '🕺': 666, '🕯': 667, '🙀': 668, 'ॉ': 669, '😲': 670, '🔚': 671, '🔨': 672, '🐒': 673, '𝐂': 674, '𝐚': 675, '𝐩': 676, '𝐭': 677, '𝐫': 678, '𝟔': 679, '𝟏': 680, '𝟐': 681, '𝐉': 682, '𝐮': 683, '𝐧': 684, '𝐖': 685, '𝐢': 686, '𝐬': 687, '︎': 688, 'า': 689, 'ไ': 690, 'แ': 691, 'ล': 692, '้': 693, 'ว': 694, 'ร': 695, 'ึ': 696, 'ง': 697, 'ข': 698, 'ณ': 699, 'ย': 700, 'ู': 701, 'ั': 702, '🤑': 703, 'ں': 704, 'ہ': 705, '★': 706, '⚔': 707, '🇷': 708, '☀': 709, '\\U0001f9f8': 710, 'ň': 711, '👐': 712, '🍀': 713, '🙅': 714, '⚪': 715, '\\U000e0073': 716, '\\U000e0063': 717, '\\U000e0074': 718, '🛍': 719, 'ò': 720, '£': 721, '€': 722, '⭐': 723, 'à': 724, '🦄': 725, '🍱': 726, '⚽': 727, '👞': 728, '\\U0001f97e': 729, '👟': 730, '😼': 731, '🌊': 732, '℅': 733, '🐥': 734, '🐿': 735, '🔈': 736, '🔪': 737, '⌚': 738, '▂': 739, '🍟': 740, '🏋': 741, '🐶': 742, '¥': 743, 'ਣ': 744, 'ਸ': 745, 'ਨ': 746, 'ਕ': 747, 'ੋ': 748, 'ਗ': 749, 'ੇ': 750, 'ਾ': 751, 'ਫ': 752, 'ਿ': 753, '―': 754, 'ì': 755, '🇨': 756, '🌳': 757, 'غ': 758, 'ط': 759, 'خ': 760, 'ز': 761, '🐮': 762, '🔁': 763, '\\U0001f9b3': 764, '📻': 765, '🌄': 766, '☔': 767, 'μ': 768, '🐓': 769, '❇': 770, '🇪': 771, 'ঈ': 772, 'দ': 773, 'ম': 774, 'ো': 775, 'ব': 776, 'া': 777, 'র': 778, 'ক': 779, '°': 780, '이': 781, '나': 782, '경': 783, '🐕': 784, '👅': 785, 'گ': 786, '🔔': 787, '🔐': 788, '🤡': 789, '🐐': 790, '\\U0001f96d': 791, '👹': 792, '📿': 793, '멀': 794, '티': 795, '뷰': 796, '와': 797, '함': 798, '께': 799, '즐': 800, '는': 801, '머': 802, '터': 803, '실': 804, '황': 805, '생': 806, '중': 807, '계': 808, '만': 809, '립': 810, '니': 811, '😵': 812, '🎟': 813, '🕌': 814, '💟': 815, 'औ': 816, '🏡': 817, '⛲': 818, 'δ': 819, 'ʰ': 820, 'ᵈ': 821, 'ʳ': 822, 'ᶜ': 823, 'ᵗ': 824, 'ᵛ': 825, 'ᵏ': 826, '😿': 827, '🤕': 828, '🎥': 829, '🤐': 830, '🔟': 831, '🎆': 832, '🎗': 833, 'は': 834, '🦅': 835, '誕': 836, '生': 837, '当': 838, '、': 839, 'イ': 840, 'ベ': 841, 'ト': 842, 'ス': 843, 'テ': 844, 'ジ': 845, 'が': 846, 'つ': 847, 'い': 848, 'に': 849, '開': 850, '放': 851, 'べ': 852, 'て': 853, 'パ': 854, 'ズ': 855, 'ル': 856, 'を': 857, 'ク': 858, 'リ': 859, 'ア': 860, 'る': 861, 'と': 862, 'ム': 863, 'ビ': 864, 'ま': 865, 'ỉ': 866, 'ư': 867, 'ờ': 868, '⇒': 869, '⛽': 870, '👶': 871, '𝗣': 872, '𝘂': 873, '𝗯': 874, '𝗹': 875, '𝗿': 876, '𝘃': 877, '𝗺': 878, '𝗮': 879, '𝗴': 880, '😦': 881, '™': 882, '📈': 883, '⚕': 884, '📣': 885, 'м': 886, 'о': 887, 'д': 888, 'к': 889, 'р': 890, 'т': 891, '🇾': 892, 'ص': 893, '🌌': 894, '👒': 895, '🥇': 896, '⚘': 897, '💍': 898, '\\U0001f974': 899, '\\U0001f92e': 900}\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           (None, 160)               0         \n",
            "_________________________________________________________________\n",
            "embedding_10 (Embedding)     (None, 160, 900)          810900    \n",
            "_________________________________________________________________\n",
            "conv1d_55 (Conv1D)           (None, 158, 256)          691456    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_59 (LeakyReLU)   (None, 158, 256)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_28 (MaxPooling (None, 52, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_56 (Conv1D)           (None, 50, 256)           196864    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_60 (LeakyReLU)   (None, 50, 256)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_29 (MaxPooling (None, 16, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_57 (Conv1D)           (None, 14, 256)           196864    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_61 (LeakyReLU)   (None, 14, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_58 (Conv1D)           (None, 12, 256)           196864    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_62 (LeakyReLU)   (None, 12, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_59 (Conv1D)           (None, 10, 256)           196864    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_63 (LeakyReLU)   (None, 10, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_60 (Conv1D)           (None, 8, 256)            196864    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_64 (LeakyReLU)   (None, 8, 256)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_30 (MaxPooling (None, 2, 256)            0         \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 300)               668400    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1024)              308224    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_65 (LeakyReLU)   (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_66 (LeakyReLU)   (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 3)                 3075      \n",
            "=================================================================\n",
            "Total params: 4,515,975\n",
            "Trainable params: 4,515,975\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4vpe4n35odC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###### To Calculate Precision, Recall, F1-Score over All Classes\n",
        "# Class1 --- Positive\n",
        "# Class2 --- Neutral\n",
        "# Class3 --- Negative\n",
        " \n",
        "import numpy as np\n",
        "from keras.callbacks import Callback\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
        "\n",
        "class Metrics(Callback):\n",
        "  def __init__(self, logs={}):\n",
        "    self.val_f1s = []\n",
        "    self.val_recalls = []\n",
        "    self.val_precisions = []\n",
        " \n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    val_predict = (np.asarray(self.model.predict(x_test))).round()\n",
        "    val_targ = y_test\n",
        "    _val_f1 = f1_score(val_targ, val_predict,average=None)\n",
        "    _val_recall = recall_score(val_targ, val_predict,average=None)\n",
        "    _val_precision = precision_score(val_targ, val_predict,average=None)\n",
        "    self.val_f1s.append(_val_f1)\n",
        "    self.val_recalls.append(_val_recall)\n",
        "    self.val_precisions.append(_val_precision)\n",
        "    print(\" — val_f1_Class1: %f — val_f1_Class2: %f — val_f1_Class3: %f — val_precision_Class1: %f — val_precision_Class2: %f — val_precision_Class3: %f — val_recall_Class1 %f — val_recall_Class2 %f — val_recall_Class3 %f\" %(_val_f1[0], _val_f1[1], _val_f1[2], _val_precision[0], _val_precision[1], _val_precision[2], _val_recall[0], _val_recall[1], _val_recall[2]))\n",
        "    return\n",
        " \n",
        "metrics = Metrics()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvEWOzrpn3c7",
        "colab_type": "code",
        "outputId": "3de37d50-8b31-45ac-c5cf-a4dbbbc16ff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x_train, y_train,validation_data=(x_test, y_test),batch_size=128,epochs=30,verbose=1,callbacks=[metrics])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 13524 samples, validate on 1869 samples\n",
            "Epoch 1/30\n",
            "13524/13524 [==============================] - 3s 254us/step - loss: 0.3189 - acc: 0.8873 - val_loss: 1.6987 - val_acc: 0.5104\n",
            " — val_f1_Class1: 0.558502 — val_f1_Class2: 0.464462 — val_f1_Class3: 0.505451 — val_precision_Class1: 0.511429 — val_precision_Class2: 0.494753 — val_precision_Class3: 0.535714 — val_recall_Class1 0.615120 — val_recall_Class2 0.437666 — val_recall_Class3 0.478424\n",
            "Epoch 2/30\n",
            "13524/13524 [==============================] - 3s 253us/step - loss: 0.2956 - acc: 0.8985 - val_loss: 1.7727 - val_acc: 0.4949\n",
            " — val_f1_Class1: 0.290713 — val_f1_Class2: 0.580247 — val_f1_Class3: 0.457859 — val_precision_Class1: 0.670807 — val_precision_Class2: 0.451923 — val_precision_Class3: 0.582609 — val_recall_Class1 0.185567 — val_recall_Class2 0.810345 — val_recall_Class3 0.377111\n",
            "Epoch 3/30\n",
            "13524/13524 [==============================] - 3s 253us/step - loss: 0.2633 - acc: 0.9112 - val_loss: 1.8776 - val_acc: 0.5062\n",
            " — val_f1_Class1: 0.430011 — val_f1_Class2: 0.527863 — val_f1_Class3: 0.529118 — val_precision_Class1: 0.617363 — val_precision_Class2: 0.490330 — val_precision_Class3: 0.475336 — val_recall_Class1 0.329897 — val_recall_Class2 0.571618 — val_recall_Class3 0.596623\n",
            "Epoch 4/30\n",
            "13524/13524 [==============================] - 3s 252us/step - loss: 0.2503 - acc: 0.9147 - val_loss: 1.7282 - val_acc: 0.5051\n",
            " — val_f1_Class1: 0.548100 — val_f1_Class2: 0.431784 — val_f1_Class3: 0.523077 — val_precision_Class1: 0.517557 — val_precision_Class2: 0.496552 — val_precision_Class3: 0.505245 — val_recall_Class1 0.582474 — val_recall_Class2 0.381963 — val_recall_Class3 0.542214\n",
            "Epoch 5/30\n",
            "13524/13524 [==============================] - 3s 253us/step - loss: 0.2169 - acc: 0.9278 - val_loss: 2.0134 - val_acc: 0.5099\n",
            " — val_f1_Class1: 0.467672 — val_f1_Class2: 0.537923 — val_f1_Class3: 0.496780 — val_precision_Class1: 0.627168 — val_precision_Class2: 0.480208 — val_precision_Class3: 0.487365 — val_recall_Class1 0.372852 — val_recall_Class2 0.611406 — val_recall_Class3 0.506567\n",
            "Epoch 6/30\n",
            "13524/13524 [==============================] - 3s 255us/step - loss: 0.1884 - acc: 0.9394 - val_loss: 2.2120 - val_acc: 0.5088\n",
            " — val_f1_Class1: 0.501493 — val_f1_Class2: 0.513784 — val_f1_Class3: 0.507542 — val_precision_Class1: 0.595745 — val_precision_Class2: 0.486936 — val_precision_Class3: 0.481481 — val_recall_Class1 0.432990 — val_recall_Class2 0.543767 — val_recall_Class3 0.536585\n",
            "Epoch 7/30\n",
            "13524/13524 [==============================] - 3s 254us/step - loss: 0.1874 - acc: 0.9384 - val_loss: 2.0954 - val_acc: 0.5110\n",
            " — val_f1_Class1: 0.512676 — val_f1_Class2: 0.512469 — val_f1_Class3: 0.507069 — val_precision_Class1: 0.565217 — val_precision_Class2: 0.483529 — val_precision_Class3: 0.509470 — val_recall_Class1 0.469072 — val_recall_Class2 0.545093 — val_recall_Class3 0.504690\n",
            "Epoch 8/30\n",
            "13524/13524 [==============================] - 3s 253us/step - loss: 0.1651 - acc: 0.9482 - val_loss: 2.2439 - val_acc: 0.5136\n",
            " — val_f1_Class1: 0.537084 — val_f1_Class2: 0.520631 — val_f1_Class3: 0.466960 — val_precision_Class1: 0.532995 — val_precision_Class2: 0.479866 — val_precision_Class3: 0.565333 — val_recall_Class1 0.541237 — val_recall_Class2 0.568966 — val_recall_Class3 0.397749\n",
            "Epoch 9/30\n",
            "13524/13524 [==============================] - 3s 253us/step - loss: 0.1576 - acc: 0.9489 - val_loss: 2.0675 - val_acc: 0.4992\n",
            " — val_f1_Class1: 0.537409 — val_f1_Class2: 0.509158 — val_f1_Class3: 0.422803 — val_precision_Class1: 0.505295 — val_precision_Class2: 0.471719 — val_precision_Class3: 0.576052 — val_recall_Class1 0.573883 — val_recall_Class2 0.553050 — val_recall_Class3 0.333959\n",
            "Epoch 10/30\n",
            "13524/13524 [==============================] - 3s 253us/step - loss: 0.1348 - acc: 0.9572 - val_loss: 2.3312 - val_acc: 0.5067\n",
            " — val_f1_Class1: 0.541292 — val_f1_Class2: 0.502786 — val_f1_Class3: 0.461017 — val_precision_Class1: 0.516381 — val_precision_Class2: 0.471545 — val_precision_Class3: 0.579545 — val_recall_Class1 0.568729 — val_recall_Class2 0.538462 — val_recall_Class3 0.382739\n",
            "Epoch 11/30\n",
            "13524/13524 [==============================] - 3s 252us/step - loss: 0.1289 - acc: 0.9589 - val_loss: 2.1224 - val_acc: 0.5249\n",
            " — val_f1_Class1: 0.529148 — val_f1_Class2: 0.486370 — val_f1_Class3: 0.558872 — val_precision_Class1: 0.553471 — val_precision_Class2: 0.529687 — val_precision_Class3: 0.500743 — val_recall_Class1 0.506873 — val_recall_Class2 0.449602 — val_recall_Class3 0.632270\n",
            "Epoch 12/30\n",
            "13524/13524 [==============================] - 3s 253us/step - loss: 0.1104 - acc: 0.9660 - val_loss: 2.2752 - val_acc: 0.5249\n",
            " — val_f1_Class1: 0.491264 — val_f1_Class2: 0.560882 — val_f1_Class3: 0.487856 — val_precision_Class1: 0.611253 — val_precision_Class2: 0.479736 — val_precision_Class3: 0.557971 — val_recall_Class1 0.410653 — val_recall_Class2 0.675066 — val_recall_Class3 0.433396\n",
            "Epoch 13/30\n",
            "13524/13524 [==============================] - 3s 252us/step - loss: 0.0925 - acc: 0.9723 - val_loss: 2.6955 - val_acc: 0.5222\n",
            " — val_f1_Class1: 0.523810 — val_f1_Class2: 0.544924 — val_f1_Class3: 0.481977 — val_precision_Class1: 0.587607 — val_precision_Class2: 0.486458 — val_precision_Class3: 0.534247 — val_recall_Class1 0.472509 — val_recall_Class2 0.619363 — val_recall_Class3 0.439024\n",
            "Epoch 14/30\n",
            "13524/13524 [==============================] - 3s 252us/step - loss: 0.0932 - acc: 0.9699 - val_loss: 2.8203 - val_acc: 0.5019\n",
            " — val_f1_Class1: 0.525497 — val_f1_Class2: 0.529083 — val_f1_Class3: 0.404040 — val_precision_Class1: 0.528696 — val_precision_Class2: 0.457447 — val_precision_Class3: 0.617761 — val_recall_Class1 0.522337 — val_recall_Class2 0.627321 — val_recall_Class3 0.300188\n",
            "Epoch 15/30\n",
            "13524/13524 [==============================] - 3s 252us/step - loss: 0.0846 - acc: 0.9724 - val_loss: 2.6329 - val_acc: 0.5243\n",
            " — val_f1_Class1: 0.509804 — val_f1_Class2: 0.558528 — val_f1_Class3: 0.474540 — val_precision_Class1: 0.593607 — val_precision_Class2: 0.481731 — val_precision_Class3: 0.561538 — val_recall_Class1 0.446735 — val_recall_Class2 0.664456 — val_recall_Class3 0.410882\n",
            "Epoch 16/30\n",
            "13524/13524 [==============================] - 3s 254us/step - loss: 0.0801 - acc: 0.9738 - val_loss: 2.4629 - val_acc: 0.5120\n",
            " — val_f1_Class1: 0.527961 — val_f1_Class2: 0.511687 — val_f1_Class3: 0.489224 — val_precision_Class1: 0.506309 — val_precision_Class2: 0.488540 — val_precision_Class3: 0.574684 — val_recall_Class1 0.551546 — val_recall_Class2 0.537135 — val_recall_Class3 0.425891\n",
            "Epoch 17/30\n",
            "13524/13524 [==============================] - 3s 253us/step - loss: 0.0792 - acc: 0.9738 - val_loss: 2.5936 - val_acc: 0.5179\n",
            " — val_f1_Class1: 0.480987 — val_f1_Class2: 0.543266 — val_f1_Class3: 0.510304 — val_precision_Class1: 0.598465 — val_precision_Class2: 0.478305 — val_precision_Class3: 0.534979 — val_recall_Class1 0.402062 — val_recall_Class2 0.628647 — val_recall_Class3 0.487805\n",
            "Epoch 18/30\n",
            "13524/13524 [==============================] - 3s 253us/step - loss: 0.0802 - acc: 0.9760 - val_loss: 2.7082 - val_acc: 0.5131\n",
            " — val_f1_Class1: 0.518851 — val_f1_Class2: 0.534111 — val_f1_Class3: 0.464088 — val_precision_Class1: 0.543233 — val_precision_Class2: 0.476587 — val_precision_Class3: 0.564516 — val_recall_Class1 0.496564 — val_recall_Class2 0.607427 — val_recall_Class3 0.393996\n",
            "Epoch 19/30\n",
            "13524/13524 [==============================] - 3s 252us/step - loss: 0.0525 - acc: 0.9825 - val_loss: 3.0813 - val_acc: 0.5078\n",
            " — val_f1_Class1: 0.462827 — val_f1_Class2: 0.545656 — val_f1_Class3: 0.479918 — val_precision_Class1: 0.592493 — val_precision_Class2: 0.468186 — val_precision_Class3: 0.531963 — val_recall_Class1 0.379725 — val_recall_Class2 0.653846 — val_recall_Class3 0.437148\n",
            "Epoch 20/30\n",
            "13524/13524 [==============================] - 3s 252us/step - loss: 0.0854 - acc: 0.9721 - val_loss: 2.9231 - val_acc: 0.5147\n",
            " — val_f1_Class1: 0.513562 — val_f1_Class2: 0.532787 — val_f1_Class3: 0.482684 — val_precision_Class1: 0.541985 — val_precision_Class2: 0.476939 — val_precision_Class3: 0.570332 — val_recall_Class1 0.487973 — val_recall_Class2 0.603448 — val_recall_Class3 0.418386\n",
            "Epoch 21/30\n",
            "13524/13524 [==============================] - 3s 252us/step - loss: 0.0529 - acc: 0.9822 - val_loss: 2.6444 - val_acc: 0.5110\n",
            " — val_f1_Class1: 0.496047 — val_f1_Class2: 0.519243 — val_f1_Class3: 0.515235 — val_precision_Class1: 0.583721 — val_precision_Class2: 0.481314 — val_precision_Class3: 0.507273 — val_recall_Class1 0.431271 — val_recall_Class2 0.563660 — val_recall_Class3 0.523452\n",
            "Epoch 22/30\n",
            "13524/13524 [==============================] - 3s 253us/step - loss: 0.0536 - acc: 0.9823 - val_loss: 2.9936 - val_acc: 0.5126\n",
            " — val_f1_Class1: 0.521038 — val_f1_Class2: 0.510025 — val_f1_Class3: 0.508806 — val_precision_Class1: 0.543925 — val_precision_Class2: 0.483373 — val_precision_Class3: 0.531697 — val_recall_Class1 0.500000 — val_recall_Class2 0.539788 — val_recall_Class3 0.487805\n",
            "Epoch 23/30\n",
            "13524/13524 [==============================] - 3s 253us/step - loss: 0.0655 - acc: 0.9794 - val_loss: 2.7143 - val_acc: 0.5249\n",
            " — val_f1_Class1: 0.544651 — val_f1_Class2: 0.537673 — val_f1_Class3: 0.480423 — val_precision_Class1: 0.561020 — val_precision_Class2: 0.492818 — val_precision_Class3: 0.550971 — val_recall_Class1 0.529210 — val_recall_Class2 0.591512 — val_recall_Class3 0.425891\n",
            "Epoch 24/30\n",
            "13524/13524 [==============================] - 3s 253us/step - loss: 0.0528 - acc: 0.9829 - val_loss: 3.0969 - val_acc: 0.5201\n",
            " — val_f1_Class1: 0.546689 — val_f1_Class2: 0.523926 — val_f1_Class3: 0.480603 — val_precision_Class1: 0.540268 — val_precision_Class2: 0.487443 — val_precision_Class3: 0.564557 — val_recall_Class1 0.553265 — val_recall_Class2 0.566313 — val_recall_Class3 0.418386\n",
            "Epoch 25/30\n",
            "13524/13524 [==============================] - 3s 253us/step - loss: 0.0601 - acc: 0.9793 - val_loss: 2.6664 - val_acc: 0.5185\n",
            " — val_f1_Class1: 0.512428 — val_f1_Class2: 0.504905 — val_f1_Class3: 0.540728 — val_precision_Class1: 0.577586 — val_precision_Class2: 0.498065 — val_precision_Class3: 0.502415 — val_recall_Class1 0.460481 — val_recall_Class2 0.511936 — val_recall_Class3 0.585366\n",
            "Epoch 26/30\n",
            "13524/13524 [==============================] - 3s 254us/step - loss: 0.0454 - acc: 0.9850 - val_loss: 3.0629 - val_acc: 0.5206\n",
            " — val_f1_Class1: 0.497992 — val_f1_Class2: 0.552809 — val_f1_Class3: 0.486430 — val_precision_Class1: 0.599034 — val_precision_Class2: 0.479532 — val_precision_Class3: 0.548235 — val_recall_Class1 0.426117 — val_recall_Class2 0.652520 — val_recall_Class3 0.437148\n",
            "Epoch 27/30\n",
            "13524/13524 [==============================] - 3s 253us/step - loss: 0.0428 - acc: 0.9864 - val_loss: 3.1215 - val_acc: 0.5110\n",
            " — val_f1_Class1: 0.520147 — val_f1_Class2: 0.519277 — val_f1_Class3: 0.479017 — val_precision_Class1: 0.556863 — val_precision_Class2: 0.475717 — val_precision_Class3: 0.527027 — val_recall_Class1 0.487973 — val_recall_Class2 0.571618 — val_recall_Class3 0.439024\n",
            "Epoch 28/30\n",
            "13524/13524 [==============================] - 3s 252us/step - loss: 0.0472 - acc: 0.9837 - val_loss: 3.0668 - val_acc: 0.5152\n",
            " — val_f1_Class1: 0.532637 — val_f1_Class2: 0.530922 — val_f1_Class3: 0.455696 — val_precision_Class1: 0.539683 — val_precision_Class2: 0.473958 — val_precision_Class3: 0.589286 — val_recall_Class1 0.525773 — val_recall_Class2 0.603448 — val_recall_Class3 0.371482\n",
            "Epoch 29/30\n",
            "13524/13524 [==============================] - 3s 253us/step - loss: 0.0451 - acc: 0.9851 - val_loss: 2.9917 - val_acc: 0.5115\n",
            " — val_f1_Class1: 0.495238 — val_f1_Class2: 0.534884 — val_f1_Class3: 0.489119 — val_precision_Class1: 0.555556 — val_precision_Class2: 0.476190 — val_precision_Class3: 0.546296 — val_recall_Class1 0.446735 — val_recall_Class2 0.610080 — val_recall_Class3 0.442777\n",
            "Epoch 30/30\n",
            "13524/13524 [==============================] - 3s 252us/step - loss: 0.0431 - acc: 0.9849 - val_loss: 3.0708 - val_acc: 0.5179\n",
            " — val_f1_Class1: 0.500982 — val_f1_Class2: 0.527459 — val_f1_Class3: 0.519849 — val_precision_Class1: 0.584862 — val_precision_Class2: 0.483942 — val_precision_Class3: 0.523810 — val_recall_Class1 0.438144 — val_recall_Class2 0.579576 — val_recall_Class3 0.515947\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2ce49532b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUXQheLVNDyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}